{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cifar10_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeXLLbFcq8CA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbYdrb_wq8CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDiniPD1q8CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V52GZUiq8CZ",
        "colab_type": "code",
        "outputId": "3c169808-9c45-44a7-fccd-d9a919aa9df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    print(img.shape)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 122])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "    4     2     0     4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUv3fWW3q8Ce",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL2H46Evq8Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 100)\n",
        "        self.fc3 = nn.Linear(100, 10)\n",
        "        self.smax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.smax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = LeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvPLb0sq8Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVa_8kRaq8Ct",
        "colab_type": "code",
        "outputId": "352d6a18-1bf2-45ae-96ca-d47c407b2bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(15):  # loop over the dataset 15 times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.691\n",
            "[1,  4000] loss: 1.571\n",
            "[1,  6000] loss: 1.561\n",
            "[1,  8000] loss: 1.562\n",
            "[1, 10000] loss: 1.629\n",
            "[1, 12000] loss: 1.601\n",
            "[1, 14000] loss: 1.575\n",
            "[2,  2000] loss: 1.557\n",
            "[2,  4000] loss: 1.585\n",
            "[2,  6000] loss: 1.566\n",
            "[2,  8000] loss: 1.563\n",
            "[2, 10000] loss: 1.606\n",
            "[2, 12000] loss: 1.562\n",
            "[2, 14000] loss: 1.583\n",
            "[3,  2000] loss: 1.633\n",
            "[3,  4000] loss: 1.604\n",
            "[3,  6000] loss: 1.645\n",
            "[3,  8000] loss: 1.645\n",
            "[3, 10000] loss: 1.577\n",
            "[3, 12000] loss: 1.622\n",
            "[3, 14000] loss: 1.577\n",
            "[4,  2000] loss: 1.611\n",
            "[4,  4000] loss: 1.655\n",
            "[4,  6000] loss: 1.588\n",
            "[4,  8000] loss: 1.562\n",
            "[4, 10000] loss: 1.596\n",
            "[4, 12000] loss: 1.635\n",
            "[4, 14000] loss: 1.567\n",
            "[5,  2000] loss: 1.569\n",
            "[5,  4000] loss: 1.670\n",
            "[5,  6000] loss: 1.612\n",
            "[5,  8000] loss: 1.580\n",
            "[5, 10000] loss: 1.564\n",
            "[5, 12000] loss: 1.681\n",
            "[5, 14000] loss: 1.702\n",
            "[6,  2000] loss: 1.590\n",
            "[6,  4000] loss: 1.592\n",
            "[6,  6000] loss: 1.610\n",
            "[6,  8000] loss: 1.593\n",
            "[6, 10000] loss: 1.701\n",
            "[6, 12000] loss: 1.616\n",
            "[6, 14000] loss: 1.687\n",
            "[7,  2000] loss: 1.637\n",
            "[7,  4000] loss: 1.603\n",
            "[7,  6000] loss: 1.592\n",
            "[7,  8000] loss: 1.576\n",
            "[7, 10000] loss: 1.573\n",
            "[7, 12000] loss: 1.591\n",
            "[7, 14000] loss: 1.673\n",
            "[8,  2000] loss: 1.620\n",
            "[8,  4000] loss: 1.572\n",
            "[8,  6000] loss: 1.595\n",
            "[8,  8000] loss: 1.574\n",
            "[8, 10000] loss: 1.642\n",
            "[8, 12000] loss: 1.613\n",
            "[8, 14000] loss: 1.583\n",
            "[9,  2000] loss: 1.582\n",
            "[9,  4000] loss: 1.590\n",
            "[9,  6000] loss: 1.589\n",
            "[9,  8000] loss: 1.592\n",
            "[9, 10000] loss: 1.582\n",
            "[9, 12000] loss: 1.657\n",
            "[9, 14000] loss: 1.714\n",
            "[10,  2000] loss: 1.587\n",
            "[10,  4000] loss: 1.611\n",
            "[10,  6000] loss: 1.679\n",
            "[10,  8000] loss: 1.662\n",
            "[10, 10000] loss: 1.729\n",
            "[10, 12000] loss: 1.684\n",
            "[10, 14000] loss: 1.664\n",
            "[11,  2000] loss: 1.599\n",
            "[11,  4000] loss: 1.592\n",
            "[11,  6000] loss: 1.575\n",
            "[11,  8000] loss: 1.590\n",
            "[11, 10000] loss: 1.607\n",
            "[11, 12000] loss: 1.624\n",
            "[11, 14000] loss: 1.645\n",
            "[12,  2000] loss: 1.705\n",
            "[12,  4000] loss: 1.644\n",
            "[12,  6000] loss: 1.613\n",
            "[12,  8000] loss: 1.580\n",
            "[12, 10000] loss: 1.597\n",
            "[12, 12000] loss: 1.606\n",
            "[12, 14000] loss: 1.653\n",
            "[13,  2000] loss: 1.635\n",
            "[13,  4000] loss: 1.600\n",
            "[13,  6000] loss: 1.601\n",
            "[13,  8000] loss: 1.587\n",
            "[13, 10000] loss: 1.613\n",
            "[13, 12000] loss: 1.618\n",
            "[13, 14000] loss: 1.662\n",
            "[14,  2000] loss: 1.653\n",
            "[14,  4000] loss: 1.711\n",
            "[14,  6000] loss: 1.750\n",
            "[14,  8000] loss: 1.618\n",
            "[14, 10000] loss: 1.656\n",
            "[14, 12000] loss: 1.736\n",
            "[14, 14000] loss: 1.662\n",
            "[15,  2000] loss: 1.600\n",
            "[15,  4000] loss: 1.584\n",
            "[15,  6000] loss: 1.599\n",
            "[15,  8000] loss: 1.584\n",
            "[15, 10000] loss: 1.600\n",
            "[15, 12000] loss: 1.605\n",
            "[15, 14000] loss: 1.600\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkt6Wa0wq8C4",
        "colab_type": "text"
      },
      "source": [
        "**Testing...**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeqxI83Mq8C6",
        "colab_type": "code",
        "outputId": "5f9c3afe-78aa-4ff0-f374-0056fa9b7642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 122])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEe1JREFUeJzt3XnQFdWZx/HvE6IIWqWghqBSiIyS\nQuOKBHcjRlERTKKRRDMarWBZGolREVzKMtHE4JQzY4JQGB3XCm5oKFcY3GJFMTC4IIiCEcSAqBjc\nKlHwmT9u93nPK/fl7n3f2+/vU0W9z+3l9mn65XD69DlPm7sjIiL58ZVmF0BEROpLFbuISM6oYhcR\nyRlV7CIiOaOKXUQkZ1Sxi4jkjCp2EZGcqaliN7MRZrbEzJaa2YR6FUpERKpn1U5QMrNuwGvAd4CV\nwF+BH7r7ovoVT0REKvXVGvYdCix19zcAzGw6MBrosGI3M01zFRGp3Hvuvn25G9fSFbMj8Fb0eWWy\nrB0zG2tm88xsXg3HEhHpypZXsnEtLfayuPs0YBqoxS4ikoVaWuxvA/2izzsly0REpIlqqdj/Cuxq\nZgPMbHNgDDCzPsUSEZFqVd0V4+7rzexc4DGgG3Czu79St5KJiEhVqh7uWNXB1McuIlKN+e4+pNyN\nNfNURCRnVLGLiOSMKnYRkZxRxS4ikjOq2EVEckYVu4hIzqhiFxHJmYbnipF8uvDCC0Pco0ePEO+5\n554hPvHEEzfab8qUKSF+9tlnQ3z77bfXu4giXZZa7CIiOaOZp1KRu+66CyjeGq/UsmXLQnzkkUcC\nsGLFipq/t6vZbbfdQvzqq6+GeNy4cQD87ne/y7xMncmWW24JwLXXXhuWnXXWWSGeP39+iE866SQA\nli+vKEtuFjTzVESkK1PFLiKSM3p4KiWl3S9Qugsm7gp47LHHANhll13CsuOPPz7EAwcODPGpp54K\nwK9//evaCtsF7bPPPiH+4osvQvz223o9AsAOO+wAwE9/+tOwLP572m+//UI8cuRIACZPnpxR6RpD\nLXYRkZxRxS4ikjPqipGihgxpewD/3e9+d6P1r7zS9k6VUaNGhfi9994L8ccffwzA5ptvHpY999xz\nId5rr71C3Lt37xpL3HXtvffeIf7kk09CPGPGjGYUp1PYfvvtQ3zLLbc0ryBNoha7iEjOqGIXEcmZ\nXHTFxCM10ifff//738Oyf/7znyG+8847Q7x69WoAli5d2ugitpy+ffuG2MxCnHbBHH300WHZqlWr\nNvldcfqBwYMHF93moYceqqqcXdU3v/nNEP/sZz8L8W233daM4nQK5513XohPOOGEEA8dOrTs7zj0\n0EMB+MpX2tq8L774YoiffvrpWoqYmZItdjO72czWmNnCaFlvM5ttZq8nP3s1tpgiIlKukikFzOxQ\n4GPgNnffI1k2CVjr7teY2QSgl7tfXPJgDUop8MYbb4R45513Lnu/jz76CGj/ILCeVq5cGeJJkyaF\neN68eQ05XqP0798/xOnf2dq1a8veP27x7LHHHkW3SVMKPPHEE9UUscuJ71LvvvvuEH/7298O8VNP\nPZVpmZptw4YNIY7HqZcSt86L7RenFzj55JNDHKciyEB9Uwq4+9PAl/8VjwZuTeJbgRMQEZFOodo+\n9j7unnasrgb6dLShmY0FxlZ5HBERqVDND0/d3TfVxeLu04Bp0LiumHiqcDo2etGiRWFZ/MAunn59\n+OGHAzBs2LCw7K233gpxv379Nnnc9evXh/jdd98NcfzgMRVnLWy1rphqM91ddNFFQPvsg7G5c+cW\njaW08ePHhzi+Pq32u1Wrhx9+OMRxl0ol3n///RCncy/i7scBAwaE+Pnnnw9xt27dqjpeFqod7viO\nmfUFSH6uqV+RRESkFtVW7DOB05L4NOBP9SmOiIjUqmRXjJn9ETgc2M7MVgJXANcAd5vZmcBy4AeN\nLGQpc+bMKRqnHn300aL79epVGKUZd8/Et7L777//Jo8bj49/7bXXQrx48WKg/TT5eOROnqXZ8QB+\n+ctfAu1TCqxZ03ZzN3HixBB/+umnGZSu9aWjvuKUD/HvXpxSIM8OO+wwAAYNGhSWxSNaSo2KmTp1\naohnzZoV4nXr1gFwxBFHhGWXXnpp0e84++yzgfave+wsSlbs7v7DDlYNr3NZRESkDpRSQEQkZ3KR\nUqBaH3zwAQCPP/540fXFunU68v3vfz/EaRfPyy+/HJZNnz69miK2nLiLIO6CScUv7ehqE2jqIe2C\niMUjsvIsnnyY/nvabrvtSu6Xjhq67777wrIrr7wyxMW6AeORRmPHto3WjrNGppMOt9hii7Ds97//\nfYg///zzkmVrFLXYRURypku32Gv1ta99LcQ33HBDiNPxtOnDQ6hsCn6reeCBB0J81FFHbbQ+Tkx1\n2WWXZVKmvIqTf6XidBV5ttlmm4W4VEs9vhscM2YM0P5dAaXELfbf/OY3Ib7uuutC3LNnT6D93//M\nmTNDvGzZsrKPV29qsYuI5IwqdhGRnFFXTA3OOeecEMcPVdKHskuWLMm8TFmJ0yYceOCBIe7evXuI\n01vfq666KixLp2xL+Q444IAQ/+QnPwFgwYIFYdns2bMzL1NnFM9BOeOMM0JcSRdMMXH3yimnnBLi\nUvNcmkktdhGRnFHFLiKSM+qKqdBBBx0U4gkTJhTdJn0t18KFC4uuz4N4TPC2225bdJs77rgDaO7o\ngDwYPrxtkneapiJOkxGntugqimVy/Na3vtWQY8WvhoyPW6wM8fj4U089tSHlKYda7CIiOaOKXUQk\nZ9QVU6Fjjz02xPGEiTj9wLPPPptpmbI0atQoAPbdd9+i65988skQX3HFFVkUKffSl8cApO8ovvfe\ne5tVnKY566yzQlzJO01rdfzxx4c4zgSbliEuS2f5nVeLXUQkZ9RiL1OPHj0AGDFiRFj22WefhTj+\nn7qZyX8aIX44eskllwDt71ZiL7zwQog1Zr16X//610N8yCGHhDidG3H//fdnXqZmi1vOjZLOR4lf\np5n+znckTsLWWf7tq8UuIpIzqthFRHJGXTFluuiii4D2D0/iscR/+ctfMi9TVi644IIQF5tGHWd3\n7CwPj1rd6aefHuI4i+gjjzzShNJ0Helr8OJ0IR158803gfbXasWKFY0oVsVKttjNrJ+ZPWFmi8zs\nFTMblyzvbWazzez15GevxhdXRERKKacrZj1wgbsPBoYB55jZYGACMMfddwXmJJ9FRKTJynmZ9Spg\nVRJ/ZGaLgR2B0cDhyWa3Ak8CFzeklE1y3HHHhfjyyy8H4MMPPwzLfvWrX2Vepmb4xS9+scn15557\nbog1EqY++vfvX3R5mjlU6ufhhx8O8aBBg8reb/HixQD8+c9/rnuZalVRH7uZ7QzsA8wF+iSVPsBq\noE8H+4wFxhZbJyIi9Vf2qBgz2wq4D/i5u38Yr/PCdDgvtp+7T3P3Ie4+pNh6ERGpr7Ja7Ga2GYVK\n/U53n5EsfsfM+rr7KjPrC6xpVCGzFE/Guf7660PcrVs3oP1tW55TB1QizTgIlU3QWLdu3Ub7xROf\ntt5666L79epVeE5//vnnlzzGhg0bALj44rZewmJvpe9sOpqM8+CDD2Zcks6joyyLqWOOOabofjfe\neCPQ/uUwsfi7KklVMHLkyLK3zVo5o2IMuAlY7O7XRatmAqcl8WnAn+pfPBERqVQ5LfaDgB8DL5tZ\nOl/8EuAa4G4zOxNYDvygMUVsvLQ1Du3Hpg8YMCDEaU7x9CGqtHnppZeq2u+ee+4J8apVhcc1ffq0\nPao5+eSTaytYZPXq1SG++uqr6/a99RSnDoj/HqRgypQpIZ40adJG6+O7mWIt73Ja46W2mTp1asnv\n6AzKGRXzDGAdrB7ewXIREWkSpRQQEckZpRQABg4cGOL99tuv6DbpWO6u+Jq3+IHx6NGj6/a9J510\nUtnbrl+/PsTFbpfjN8nHb6tPPfPMMxWWLnvpKxWhfffgggULQvzUU09lWqbOZMaMGSFOU3yk2Rjr\nJc3UmI5RBxg7tm20dtpl2NmpxS4ikjOq2EVEcqZLd8Wk07ZnzZpVdH16uwdde/zw9773vRCPHz8e\n6PhFG7Hdd98dKG90y8033wy0Zcz7svg2PL5NzoOePXsC7V+7GItfg5eOy++Kli9fHuIxY8YA7buv\nxo0bV/Mx0hFTkydPrvm7mkktdhGRnFHFLiKSM5a+9TyTg5lld7AypLddEydOLLp+6NChIS420kKk\nHtJurXjEy5o1bRk6fvSjH4W4FdIhNEv8PuJ4JEuaniEeOTVt2rQQx6kKFi1aBHSeF2ZE5leSb0st\ndhGRnOlyLfZ42vZDDz0EwFZbbVV0W7XYRaSTUItdRKQrU8UuIpIzXW4c+8EHHxziYl0wccoAveZN\nRFqRWuwiIjmjil1EJGe6XFdMMS+++GKIhw9vSzG/du3aZhRHRKQmarGLiOSMKnYRkZwpOUHJzLYA\nnga6U+i6udfdrzCzAcB0YFtgPvBjd/+sxHc1fYKSiEgLqvsEpX8BR7j7XsDewAgzGwb8FvhPd/83\n4APgzGpKKyIi9VWyYveCdED3ZskfB44A0kTRtwInFNldREQyVlYfu5l1M7MXgDXAbGAZ8A93T19E\nuRLYsTFFFBGRSpRVsbv7BnffG9gJGAp8o9wDmNlYM5tnZsqiJSKSgYpGxbj7P4AngAOAbcwsHQe/\nE/B2B/tMc/chlXT8i4hI9UpW7Ga2vZltk8Q9gO8AiylU8Ccmm50G/KlRhRQRkfKVM/O0L3CrmXWj\n8B/B3e7+oJktAqab2VXAAuCmBpZTRETKlPWLNt4FPgHey+yg2doOnVsr0rm1pq50bv3dfftyd860\nYgcws3l57W/XubUmnVtr0rl1TCkFRERyRhW7iEjONKNin9aEY2ZF59aadG6tSefWgcz72EVEpLHU\nFSMikjOq2EVEcibTit3MRpjZEjNbamYTsjx2vZlZPzN7wswWmdkrZjYuWd7bzGab2evJz17NLms1\nksRvC8zsweTzADObm1y7u8xs82aXsRpmto2Z3Wtmr5rZYjM7IEfX7Pzkd3Ghmf3RzLZo1etmZjeb\n2RozWxgtK3qdrOD65BxfMrN9m1fy0jo4t2uT38mXzOz+dLZ/sm5icm5LzOzoco6RWcWezFydDBwD\nDAZ+aGaDszp+A6wHLnD3wcAw4JzkfCYAc9x9V2BO8rkVjaOQOiKVl/z7/w086u7fAPaicI4tf83M\nbEfgPGCIu+8BdAPG0LrX7RZgxJeWdXSdjgF2Tf6MBaZkVMZq3cLG5zYb2MPd9wReAyYCJHXKGGD3\nZJ8bkrp0k7JssQ8Flrr7G8mblqYDozM8fl25+yp3/78k/ohCBbEjhXO6NdmsJfPUm9lOwHHAH5LP\nRg7y75vZ1sChJOkv3P2zJLFdy1+zxFeBHklyvp7AKlr0urn708CX3ybf0XUaDdyWvDviOQoJCvtm\nU9LKFTs3d58VpUF/jkJiRSic23R3/5e7/w1YSqEu3aQsK/Ydgbeiz7nJ4W5mOwP7AHOBPu6+Klm1\nGujTpGLV4r+A8cAXyedtyUf+/QHAu8D/JN1MfzCzLcnBNXP3t4H/AFZQqNDXUXhlZR6uW6qj65S3\nuuUM4JEkrurc9PC0Rma2FXAf8HN3/zBe54WxpC01ntTMRgJr3H1+s8vSAF8F9gWmuPs+FPIWtet2\nacVrBpD0N4+m8J/XDsCWbHy7nxutep1KMbNLKXTz3lnL92RZsb8N9Is+d5jDvVWY2WYUKvU73X1G\nsvid9DYw+bmmWeWr0kHAKDN7k0J32REU+qXLyr/fya0EVrr73OTzvRQq+la/ZgBHAn9z93fd/XNg\nBoVrmYfrluroOuWibjGz04GRwCneNsGoqnPLsmL/K7Br8pR+cwoPBGZmePy6SvqdbwIWu/t10aqZ\nFPLTQwvmqXf3ie6+k7vvTOEaPe7up5CD/Pvuvhp4y8wGJYuGA4to8WuWWAEMM7Oeye9mem4tf90i\nHV2nmcC/J6NjhgHroi6blmBmIyh0f45y90+jVTOBMWbW3cwGUHhA/HzJL3T3zP4Ax1J44rsMuDTL\nYzfgXA6mcCv4EvBC8udYCv3Rc4DXgf8Feje7rDWc4+HAg0m8S/ILtRS4B+je7PJVeU57A/OS6/YA\n0Csv1wy4EngVWAjcDnRv1esG/JHCs4LPKdxpndnRdQKMwoi7ZcDLFEYGNf0cKjy3pRT60tO6ZGq0\n/aXJuS0BjinnGEopICKSM3p4KiKSM6rYRURyRhW7iEjOqGIXEckZVewiIjmjil1EJGdUsYuI5Mz/\nA7iKQRl17gFbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:      7     2     1     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj9kVGI8q8DE",
        "colab_type": "code",
        "outputId": "0bc34a0d-408c-4fbf-d5db-908d4032fec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "outputs = model(images)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afXXCA6Cq8DL",
        "colab_type": "code",
        "outputId": "c14a8639-9e2d-42e9-f1d9-56b157175a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:      7     2     1     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnU94796q8DS",
        "colab_type": "code",
        "outputId": "da29d98e-062e-40d7-e0dd-150453cd0803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZoGRHZ0q8DY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d3d8d805-875b-4824-d6b8-524d00edfe2d"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of     0 : 89 %\n",
            "Accuracy of     1 : 94 %\n",
            "Accuracy of     2 : 74 %\n",
            "Accuracy of     3 : 83 %\n",
            "Accuracy of     4 : 97 %\n",
            "Accuracy of     5 : 69 %\n",
            "Accuracy of     6 : 96 %\n",
            "Accuracy of     7 : 85 %\n",
            "Accuracy of     8 : 89 %\n",
            "Accuracy of     9 : 90 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}